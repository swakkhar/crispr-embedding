{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anika107/Crispr-embedding/blob/main/Crispr_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWSAjFK0mdj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pos = pd.read_csv('pos1128.csv')  # specify the file path of positive data from dl-crispr\n",
        "neg = pd.read_csv('neg.csv')      # specify the file path of negative data from dl-crispr\n",
        "\n",
        "pos_df = pos\n",
        "neg_df = neg\n",
        "\n",
        "pos_array = np.array(pos)\n",
        "\n",
        "for i in range(len(pos_array)):    #remove pam from positive data\n",
        "    x = pos_array[i][0]\n",
        "    pos_array[i][0] = x[:-3]\n",
        "    x = pos_array[i][1]\n",
        "    pos_array[i][1] = x[:-3]\n",
        "\n",
        "neg_array = np.array(neg)\n",
        "for i in range(len(neg_array)):    #remove pam from negative data\n",
        "    x = neg_array[i][0]\n",
        "    neg_array[i][0] = x[:-3]\n",
        "    x = neg_array[i][1]\n",
        "    neg_array[i][1] = x[:-3]\n",
        "\n",
        "pos_df = pd.concat([pos_df, pos_df, pos_df, pos_df])\n",
        "pos_df['label'] = 1\n",
        "neg_df['label'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3lIxdiFlSAf"
      },
      "source": [
        "from dna2vec.multi_k_model import MultiKModel\n",
        "\n",
        "filepath = '/dna2vec/pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'  # specify the file path of pretrained dna2vec vectors\n",
        "mk_model = MultiKModel(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNXHHBs6ECiU"
      },
      "source": [
        "all_kmer = list()\n",
        "nucleotides = ['A', 'C', 'G', 'T']\n",
        "kmer_embedding = {}\n",
        "\n",
        "def generate_kmer(n, kmer, l):\n",
        "  if len(kmer) == l and kmer not in all_kmer:\n",
        "     all_kmer.append(kmer)\n",
        "  if len(kmer) < l:\n",
        "    kmer = kmer+n\n",
        "    for i in range(4):\n",
        "       generate_kmer(nucleotides[i], kmer, l)\n",
        "\n",
        "k = 3 #k value range[3-6]\n",
        "for i in range(4):\n",
        "   generate_kmer(nucleotides[i], \"\", k)\n",
        "\n",
        "for i in range(len(all_kmer)):\n",
        "  kmer_embedding[all_kmer[i]] = mk_model.vector(all_kmer[i]) #store values for each kmer from dna2vec pretrained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3di3fZ4cAtSG"
      },
      "source": [
        "mis = { \"AT\": 0 , \"AG\": 1, \"AC\": 2, \"TA\": 3, \"TG\": 4, \"TC\": 5, \"GA\": 6, \"GT\": 7 , \"GC\": 8, \"CA\": 9, \"CT\": 10 , \"CG\": 11}\n",
        "\n",
        "def mismatch(on, off):\n",
        "    matrix = np.zeros((12, 100),dtype = int)\n",
        "    for j in range(20):\n",
        "      if on[j] != off[j]:\n",
        "        mutation = on[j]+off[j]\n",
        "        matrix[mis[mutation]][j] = 1\n",
        "    return matrix\n",
        "\n",
        "def dna_embedding(sequence):\n",
        "    embedding = list()\n",
        "    for i in range(len(sequence)-k+1):\n",
        "        kmer= sequence[i:i+k]\n",
        "        tmp = kmer_embedding[kmer]\n",
        "        embedding.append(tmp)\n",
        "\n",
        "    embedding = np.array(embedding)\n",
        "    return embedding\n",
        "\n",
        "def on_off_add(arr, c):\n",
        "  on = arr[0]\n",
        "  off = arr[1]\n",
        "  on_embedding = dna_embedding(on)\n",
        "  off_embedding = dna_embedding(off)\n",
        "  if c == 1:\n",
        "     mis = mismatch(on,off)\n",
        "     rs = np.concatenate((on_embedding, off_embedding), axis=0)\n",
        "     rs_with_mis = np.concatenate((on_embedding, off_embedding, mis), axis = 0)\n",
        "     return rs, rs_with_mis\n",
        "  else:\n",
        "     rs = np.concatenate((on_embedding, off_embedding), axis=0)\n",
        "     return rs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mMcIOm0imoM"
      },
      "source": [
        "x,y = np.shape(pos_array)\n",
        "\n",
        "pos = list()\n",
        "neg = list()\n",
        "\n",
        "pos_with_mis = list()\n",
        "neg_with_mis = list()\n",
        "\n",
        "neg_features = dict()\n",
        "neg_mismatch = dict()\n",
        "for i in range(x):\n",
        "  rs, rs_with_mis = on_off_add(pos_array[i], 1)\n",
        "  pos.append(rs)\n",
        "  pos_with_mis.append(rs_with_mis)\n",
        "\n",
        "x,y = np.shape(neg_array)\n",
        "for i in range(x):\n",
        "  rs = on_off_add(neg_array[i], 0)\n",
        "  neg.append(rs)\n",
        "  neg_features[i] = rs\n",
        "  neg_mismatch[i] = neg_array[i]\n",
        "\n",
        "pos = np.array(pos)\n",
        "x,y,z = np.shape(pos)\n",
        "\n",
        "pos_with_mis = np.array(pos_with_mis)\n",
        "\n",
        "#Data augmentation\n",
        "\n",
        "pos_90 = np.rot90(pos,1,(1,2))\n",
        "pos_180 = np.rot90(pos_90,1,(1,2))\n",
        "pos_270 = np.rot90(pos_180,1,(1,2))\n",
        "\n",
        "pos = np.concatenate((pos, pos_90.reshape(x,y,z), pos_180.reshape(x,y,z), pos_270.reshape(x,y,z)), axis=0)\n",
        "neg = np.array(neg)\n",
        "\n",
        "x,y,z = np.shape(pos_with_mis)\n",
        "\n",
        "pos_90 = np.rot90(pos_with_mis,1,(1,2))\n",
        "pos_180 = np.rot90(pos_90,1,(1,2))\n",
        "pos_270 = np.rot90(pos_180,1,(1,2))\n",
        "\n",
        "pos_with_mis = np.concatenate((pos_with_mis, pos_90.reshape(x,y,z), pos_180.reshape(x,y,z), pos_270.reshape(x,y,z)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-_yvpRHvoPh"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Multi dimension reduction\n",
        "x, y, z = np.shape(pos)\n",
        "y_pos = np.tile(1, x)\n",
        "pos_dim_reduction = np.reshape(pos, (x, y*z))\n",
        "\n",
        "x, y, z = np.shape(neg)\n",
        "y_neg = np.tile(0, x)\n",
        "neg_dim_reduction = np.reshape(neg, (x, y*z))\n",
        "\n",
        "labels = np.concatenate((y_pos, y_neg))\n",
        "all_array = np.concatenate((pos_dim_reduction, neg_dim_reduction), axis = 0)\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "pca.fit(neg_dim_reduction)\n",
        "\n",
        "neg_pca = pca.transform(neg_dim_reduction)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPGIVdJgQw60"
      },
      "source": [
        "pca = PCA(n_components = 2)\n",
        "pca.fit(pos_dim_reduction)\n",
        "pos_pca = pca.transform(pos_dim_reduction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1014HWfB4wK2"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(pos_pca)\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "pca.fit(all_array)\n",
        "x_pca = pca.transform(all_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXvehUc38kV0"
      },
      "source": [
        "pos_pca = np.array(pos_pca).T\n",
        "neg_pca = np.array(neg_pca).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRXZe_a--jIB"
      },
      "source": [
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "pos_df['pca_x'] = pos_pca[0]\n",
        "pos_df['pca_y'] = pos_pca[1]\n",
        "neg_df['pca_x'] = neg_pca[0]\n",
        "neg_df['pca_y'] = neg_pca[1]\n",
        "\n",
        "pos_df['cluster'] = kmeans.labels_\n",
        "df = pos_df.loc[pos_df['cluster'] == 0]\n",
        "neg_df[\"distance\"] = \"\"\n",
        "\n",
        "# Calculate maximum distance from data points to center for each cluster\n",
        "\n",
        "for i in range(4):\n",
        "  df = pos_df.loc[pos_df['cluster'] == i]\n",
        "  max_dis = 0\n",
        "  for ind in df.index:\n",
        "     dis = np.sqrt(((df['pca_x'][ind]-centers[i][0])**2) + ((df['pca_y'][ind]-centers[i][1])**2))  # get distance from center of cluster\n",
        "     max_dis = max(dis, max_dis)\n",
        "  distance = list()\n",
        "  for ind in neg_df.index:\n",
        "     dis = np.sqrt(((neg_df['pca_x'][ind]-centers[i][0])**2) + ((neg_df['pca_y'][ind]-centers[i][1])**2))\n",
        "     neg_df.at[ind, \"distance\"] = dis\n",
        "  neg_df = neg_df[neg_df['distance'] > max_dis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQ6ONfOukQS"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(return_indices=True,sampling_strategy=1)\n",
        "\n",
        "# Random under sampling method for removing negative data\n",
        "\n",
        "y_neg = neg_df['label']\n",
        "y_pos = pos_df['label']\n",
        "\n",
        "y = np.concatenate((y_pos, y_neg))\n",
        "\n",
        "pos_pca = np.array(pos_pca).T\n",
        "\n",
        "neg_pca_x = neg_df['pca_x']\n",
        "neg_pca_y = neg_df['pca_y']\n",
        "neg_pca = np.column_stack((neg_pca_x, neg_pca_y))\n",
        "\n",
        "X = np.concatenate((pos_pca, neg_pca), axis = 0)\n",
        "X_rus, y_rus, id_rus = rus.fit_sample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTVS4EYSmWTh"
      },
      "source": [
        "on_target = list()\n",
        "no_editing = list()\n",
        "\n",
        "# Clean negative data which creates noise for positive data\n",
        "\n",
        "for i in range(len(X_rus)):\n",
        "    single_df = neg_df.loc[(neg_df['pca_x'] == X_rus[i][0]) & (neg_df['pca_y'] == X_rus[i][1])]\n",
        "    if len(single_df) >= 1:\n",
        "       on_target.append(single_df['ontarget'].iloc[0])\n",
        "       no_editing.append(single_df['noeditting'].iloc[0])\n",
        "\n",
        "clean_neg = np.column_stack((on_target, no_editing))\n",
        "clean_neg_array = np.array(clean_neg)\n",
        "print(np.shape(clean_neg_array))\n",
        "for i in range(len(clean_neg_array)):\n",
        "    x = clean_neg_array[i][0]\n",
        "    clean_neg_array[i][0] = x[:-3]\n",
        "    x = clean_neg_array[i][1]\n",
        "    clean_neg_array[i][1] = x[:-3]\n",
        "\n",
        "clean_neg_list = list()\n",
        "x,y = np.shape(clean_neg_array)\n",
        "\n",
        "for i in range(x):\n",
        "  clean_neg_list.append(on_off_add(clean_neg_array[i], 0))\n",
        "\n",
        "clean_neg_array = np.array(clean_neg_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eoNcZsb3pUY"
      },
      "source": [
        "clean_neg_with_mis = list()\n",
        "c = 0\n",
        "\n",
        "x,y,z = np.shape(clean_neg_array)\n",
        "y = int(y/2)\n",
        "for i in range(x):\n",
        "   found_kmer_on = list()\n",
        "   found_kmer_noedit = list()\n",
        "   for j in range(y):\n",
        "      tmp = clean_neg_array[i][j]\n",
        "      for label, val in kmer_embedding.items():\n",
        "          if (val == clean_neg_array[i][j]).all():\n",
        "             found_kmer_on.append(label)\n",
        "             break\n",
        "      for label, val in kmer_embedding.items():\n",
        "          if (val == clean_neg_array[i][j+y]).all():\n",
        "             found_kmer_noedit.append(label)\n",
        "             break\n",
        "   on = \"\"\n",
        "   for j in range(len(found_kmer_on)):\n",
        "       if j == 0:\n",
        "          on = on + found_kmer_on[j]\n",
        "       else:\n",
        "          on = on + found_kmer_on[j][k-1:]\n",
        "   noedit = \"\"\n",
        "   for j in range(len(found_kmer_noedit)):\n",
        "       if j == 0:\n",
        "          noedit = noedit + found_kmer_noedit[j]\n",
        "       else:\n",
        "          noedit = noedit + found_kmer_noedit[j][k-1:]\n",
        "   rs, rs_with_mis = on_off_add([on, noedit], 1)\n",
        "   clean_neg_with_mis.append(rs_with_mis)\n",
        "\n",
        "clean_neg_with_mis = np.array(clean_neg_with_mis)\n",
        "clean_neg_array = clean_neg_with_mis\n",
        "pos = pos_with_mis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsidOTOPRbmJ"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = np.concatenate((pos, clean_neg_array))\n",
        "y_neg = np.tile(0, len(clean_neg_array))\n",
        "y_pos = pos_df['label']\n",
        "\n",
        "y = np.concatenate((y_pos, y_neg))\n",
        "\n",
        "x, y = shuffle(x, y, random_state = 42)\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "a,b,c = np.shape(x)\n",
        "x = x.reshape(a, b, c, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q1p9YB7tSa4"
      },
      "source": [
        "from tensorflow.keras import datasets, layers, models, initializers, optimizers, losses\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def cnn_model(x, y, z):\n",
        "  model = models.Sequential()\n",
        "  he = initializers.HeNormal()\n",
        "  model.add(layers.Conv2D(input_shape=(x,y,z),kernel_initializer=he,filters=16,kernel_size=(5,5),strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "  model.add(layers.Conv2D(filters=4,kernel_size=(3,3),strides=(1,1),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(layers.Conv2D(filters=4,kernel_size=(3,3),strides=(1,1),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(layers.Conv2D(filters=4,kernel_size=(3,3),strides=(1,1),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(layers.Conv2D(filters=4,kernel_size=(1,1),strides=(1,1),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(layers.Flatten(name='flatten'))\n",
        "  model.add(layers.Dense(40, activation='relu', name='fc1'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(2, activation='sigmoid', name='output'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeRuJKarTE5m"
      },
      "source": [
        "model = cnn_model(b,c,1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(optimizer = optimizers.SGD(learning_rate = 0.0001),\n",
        "              loss = losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=7, batch_size=8, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8tUG7Q8Y6wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b096a11-ba18-4fe0-a7e9-6231b3184b88"
      },
      "source": [
        "test = pd.read_csv('test.csv')   # specifiy the file path of test data\n",
        "test_array = np.array(test)\n",
        "for i in range(len(test_array)):  # remove pam from test data\n",
        "    tmp = test_array[i][0]\n",
        "    test_array[i][0] = tmp[:-3]\n",
        "    tmp = test_array[i][1]\n",
        "    test_array[i][1] = tmp[:-3]\n",
        "\n",
        "test_list = list()\n",
        "l,z = np.shape(test_array)\n",
        "\n",
        "for i in range(l):\n",
        "  rs, rs_with_mis = on_off_add(test_array[i], 1)\n",
        "  test_list.append(rs_with_mis)\n",
        "\n",
        "test = np.array(test_list)\n",
        "f,g,h = np.shape(test)\n",
        "test = test.reshape(f, g, h, 1)\n",
        "\n",
        "predicted = model.predict(test)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(len(predicted)):\n",
        "    if (predicted[i][0]>=0.5):\n",
        "       cnt = cnt + 1\n",
        "    else:\n",
        "       y_pred.append(0)\n",
        "\n",
        "print(\"The number of predicted samples: \",cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of predicted samples:  37\n"
          ]
        }
      ]
    }
  ]
}